{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# This code is to genereate the best testing model for the Neural Network for the application\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import joblib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import classification_report as cr\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.model_selection import train_test_split, KFold\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score\r\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\r\n",
    "from scipy import stats\r\n",
    "\r\n",
    "# data preprocessing\r\n",
    "df = pd.read_csv('austinHousingData.csv')\r\n",
    "df_filtered = df[['livingAreaSqFt', 'numOfBathrooms', 'avgSchoolRating', 'numOfBedrooms', 'numOfHighSchools', 'MedianStudentsPerTeacher', 'latestPrice']]\r\n",
    "\r\n",
    "z = np.abs(stats.zscore(df_filtered))\r\n",
    "threshold = 2.5\r\n",
    "df_filtered_o = df_filtered[(z < threshold).all(axis=1)]\r\n",
    "\r\n",
    "df = df_filtered_o[['livingAreaSqFt', 'numOfBathrooms', 'avgSchoolRating', 'numOfBedrooms', 'numOfHighSchools', 'MedianStudentsPerTeacher', 'latestPrice']]\r\n",
    "df_filtered_o.to_csv(\"neuralNet_test.csv\")\r\n",
    "df = df.reset_index(drop=True)\r\n",
    "\r\n",
    "df['buckets'] = None\r\n",
    "\r\n",
    "for idx,row in df.iterrows():\r\n",
    "  if (row['latestPrice']) < 50000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 0\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 100000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 1\r\n",
    "  \r\n",
    "  elif (row['latestPrice']) < 150000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 2\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 200000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 3\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 250000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 4\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 300000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 5\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 350000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 6\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 400000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 7\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 450000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 8\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 500000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 9\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 550000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 10\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 600000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 11\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 700000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 12\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 800000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 13\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 900000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 14\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 1000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 15\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 1500000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 16\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 2000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 16\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 3000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 17\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 4000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 18\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 5000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 19\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 6000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 20\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 7000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 19\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 8000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 20\r\n",
    "\r\n",
    "  elif (row['latestPrice']) < 9000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 21\r\n",
    "\r\n",
    "  elif (row['latestPrice']) >= 10000000:\r\n",
    "    \r\n",
    "    df.iloc[idx,-1] = 22\r\n",
    "\r\n",
    "df = df.drop(columns=['latestPrice'])\r\n",
    "\r\n",
    "X = df.iloc[:,:-1].to_numpy()\r\n",
    "y = df.iloc[:,-1]\r\n",
    "\r\n",
    "# using min-max scaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X = scaler.fit_transform(X)\r\n",
    "\r\n",
    "# One-hot encoder\r\n",
    "oHe = OneHotEncoder()\r\n",
    "y = df.iloc[:,-1].to_numpy().reshape([-1,1])\r\n",
    "y = oHe.fit_transform(y, y=None).toarray()\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, test_size = 0.2)\r\n",
    "\r\n",
    "NN_model = tf.keras.models.Sequential()\r\n",
    "NN_model.add(tf.keras.layers.Dense(100,activation='relu'))\r\n",
    "NN_model.add(tf.keras.layers.Dense(80,activation='relu'))\r\n",
    "NN_model.add(tf.keras.layers.Dense(50,activation='relu'))\r\n",
    "NN_model.add(tf.keras.layers.Dense(17,activation='sigmoid'))\r\n",
    "\r\n",
    "NN_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy','mse'])\r\n",
    "NN_model.optimizer.lr = 0.2\r\n",
    "NN_model.fit(X_train, y_train, epochs=150)\r\n",
    "\r\n",
    "y_pred_train = NN_model.predict(X_train)\r\n",
    "y_pred_test = NN_model.predict(X_test)\r\n",
    "\r\n",
    "mse_nn_train = mean_squared_error(y_train, y_pred_train)\r\n",
    "mse_nn_test = mean_squared_error(y_test, y_pred_test)\r\n",
    "\r\n",
    "print(\"The neural network testing MSE is:  \", mse_nn_test)\r\n",
    "print(\"The neural network training MSE is:  \", mse_nn_train)\r\n",
    "\r\n",
    "tf.keras.models.save_model(NN_model, \"NN_model.sav\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/150\n",
      "330/330 [==============================] - 1s 699us/step - loss: 2.4475 - accuracy: 0.1558 - mse: 0.2512\n",
      "Epoch 2/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 2.3117 - accuracy: 0.1807 - mse: 0.2887\n",
      "Epoch 3/150\n",
      "330/330 [==============================] - 0s 675us/step - loss: 2.2802 - accuracy: 0.1892 - mse: 0.2991\n",
      "Epoch 4/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 2.2621 - accuracy: 0.1977 - mse: 0.3026\n",
      "Epoch 5/150\n",
      "330/330 [==============================] - 0s 781us/step - loss: 2.2406 - accuracy: 0.2021 - mse: 0.3068\n",
      "Epoch 6/150\n",
      "330/330 [==============================] - 0s 666us/step - loss: 2.2272 - accuracy: 0.2031 - mse: 0.3117\n",
      "Epoch 7/150\n",
      "330/330 [==============================] - 0s 696us/step - loss: 2.2186 - accuracy: 0.2077 - mse: 0.3141\n",
      "Epoch 8/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 2.2093 - accuracy: 0.2102 - mse: 0.3179\n",
      "Epoch 9/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 2.2010 - accuracy: 0.2106 - mse: 0.3208\n",
      "Epoch 10/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 2.1946 - accuracy: 0.2119 - mse: 0.3216\n",
      "Epoch 11/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 2.1869 - accuracy: 0.2119 - mse: 0.3233\n",
      "Epoch 12/150\n",
      "330/330 [==============================] - 0s 648us/step - loss: 2.1796 - accuracy: 0.2118 - mse: 0.3261\n",
      "Epoch 13/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 2.1732 - accuracy: 0.2157 - mse: 0.3277\n",
      "Epoch 14/150\n",
      "330/330 [==============================] - 0s 648us/step - loss: 2.1665 - accuracy: 0.2229 - mse: 0.3273\n",
      "Epoch 15/150\n",
      "330/330 [==============================] - 0s 635us/step - loss: 2.1609 - accuracy: 0.2162 - mse: 0.3292\n",
      "Epoch 16/150\n",
      "330/330 [==============================] - 0s 717us/step - loss: 2.1591 - accuracy: 0.2193 - mse: 0.3295\n",
      "Epoch 17/150\n",
      "330/330 [==============================] - 0s 717us/step - loss: 2.1514 - accuracy: 0.2173 - mse: 0.3290\n",
      "Epoch 18/150\n",
      "330/330 [==============================] - 0s 678us/step - loss: 2.1445 - accuracy: 0.2245 - mse: 0.3340\n",
      "Epoch 19/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 2.1382 - accuracy: 0.2259 - mse: 0.3341\n",
      "Epoch 20/150\n",
      "330/330 [==============================] - 0s 705us/step - loss: 2.1355 - accuracy: 0.2259 - mse: 0.3358\n",
      "Epoch 21/150\n",
      "330/330 [==============================] - 0s 669us/step - loss: 2.1282 - accuracy: 0.2263 - mse: 0.3357\n",
      "Epoch 22/150\n",
      "330/330 [==============================] - 0s 739us/step - loss: 2.1246 - accuracy: 0.2293 - mse: 0.3382\n",
      "Epoch 23/150\n",
      "330/330 [==============================] - 0s 687us/step - loss: 2.1165 - accuracy: 0.2335 - mse: 0.3404\n",
      "Epoch 24/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 2.1167 - accuracy: 0.2288 - mse: 0.3399\n",
      "Epoch 25/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 2.1126 - accuracy: 0.2263 - mse: 0.3404\n",
      "Epoch 26/150\n",
      "330/330 [==============================] - 0s 727us/step - loss: 2.1073 - accuracy: 0.2368 - mse: 0.3388\n",
      "Epoch 27/150\n",
      "330/330 [==============================] - 0s 721us/step - loss: 2.1077 - accuracy: 0.2348 - mse: 0.3417\n",
      "Epoch 28/150\n",
      "330/330 [==============================] - 0s 736us/step - loss: 2.1044 - accuracy: 0.2367 - mse: 0.3418\n",
      "Epoch 29/150\n",
      "330/330 [==============================] - 0s 696us/step - loss: 2.0974 - accuracy: 0.2334 - mse: 0.3433\n",
      "Epoch 30/150\n",
      "330/330 [==============================] - 0s 724us/step - loss: 2.0949 - accuracy: 0.2374 - mse: 0.3463\n",
      "Epoch 31/150\n",
      "330/330 [==============================] - 0s 733us/step - loss: 2.0888 - accuracy: 0.2395 - mse: 0.3473\n",
      "Epoch 32/150\n",
      "330/330 [==============================] - 0s 727us/step - loss: 2.0863 - accuracy: 0.2359 - mse: 0.3472\n",
      "Epoch 33/150\n",
      "330/330 [==============================] - 0s 699us/step - loss: 2.0862 - accuracy: 0.2417 - mse: 0.3462\n",
      "Epoch 34/150\n",
      "330/330 [==============================] - 0s 711us/step - loss: 2.0825 - accuracy: 0.2422 - mse: 0.3472\n",
      "Epoch 35/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 2.0758 - accuracy: 0.2478 - mse: 0.3506\n",
      "Epoch 36/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 2.0719 - accuracy: 0.2447 - mse: 0.3513\n",
      "Epoch 37/150\n",
      "330/330 [==============================] - 0s 666us/step - loss: 2.0702 - accuracy: 0.2443 - mse: 0.3518\n",
      "Epoch 38/150\n",
      "330/330 [==============================] - 0s 681us/step - loss: 2.0691 - accuracy: 0.2482 - mse: 0.3529\n",
      "Epoch 39/150\n",
      "330/330 [==============================] - 0s 705us/step - loss: 2.0626 - accuracy: 0.2456 - mse: 0.3523\n",
      "Epoch 40/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 2.0578 - accuracy: 0.2456 - mse: 0.3523\n",
      "Epoch 41/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 2.0547 - accuracy: 0.2528 - mse: 0.3525\n",
      "Epoch 42/150\n",
      "330/330 [==============================] - 0s 645us/step - loss: 2.0526 - accuracy: 0.2534 - mse: 0.3524\n",
      "Epoch 43/150\n",
      "330/330 [==============================] - 0s 645us/step - loss: 2.0520 - accuracy: 0.2535 - mse: 0.3524\n",
      "Epoch 44/150\n",
      "330/330 [==============================] - 0s 669us/step - loss: 2.0470 - accuracy: 0.2607 - mse: 0.3517\n",
      "Epoch 45/150\n",
      "330/330 [==============================] - 0s 696us/step - loss: 2.0465 - accuracy: 0.2491 - mse: 0.3526\n",
      "Epoch 46/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 2.0460 - accuracy: 0.2602 - mse: 0.3524\n",
      "Epoch 47/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 2.0396 - accuracy: 0.2553 - mse: 0.3508\n",
      "Epoch 48/150\n",
      "330/330 [==============================] - 0s 648us/step - loss: 2.0353 - accuracy: 0.2574 - mse: 0.3548\n",
      "Epoch 49/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 2.0318 - accuracy: 0.2549 - mse: 0.3541\n",
      "Epoch 50/150\n",
      "330/330 [==============================] - 0s 681us/step - loss: 2.0345 - accuracy: 0.2576 - mse: 0.3532\n",
      "Epoch 51/150\n",
      "330/330 [==============================] - 0s 672us/step - loss: 2.0327 - accuracy: 0.2582 - mse: 0.3553\n",
      "Epoch 52/150\n",
      "330/330 [==============================] - 0s 669us/step - loss: 2.0248 - accuracy: 0.2596 - mse: 0.3564\n",
      "Epoch 53/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 2.0259 - accuracy: 0.2594 - mse: 0.3568\n",
      "Epoch 54/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 2.0182 - accuracy: 0.2621 - mse: 0.3559\n",
      "Epoch 55/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 2.0164 - accuracy: 0.2660 - mse: 0.3569\n",
      "Epoch 56/150\n",
      "330/330 [==============================] - 0s 666us/step - loss: 2.0139 - accuracy: 0.2693 - mse: 0.3593\n",
      "Epoch 57/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 2.0110 - accuracy: 0.2644 - mse: 0.3592\n",
      "Epoch 58/150\n",
      "330/330 [==============================] - 0s 648us/step - loss: 2.0120 - accuracy: 0.2687 - mse: 0.3589\n",
      "Epoch 59/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 2.0049 - accuracy: 0.2605 - mse: 0.3577\n",
      "Epoch 60/150\n",
      "330/330 [==============================] - 0s 669us/step - loss: 2.0071 - accuracy: 0.2671 - mse: 0.3598\n",
      "Epoch 61/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 2.0063 - accuracy: 0.2625 - mse: 0.3587\n",
      "Epoch 62/150\n",
      "330/330 [==============================] - 0s 757us/step - loss: 1.9950 - accuracy: 0.2708 - mse: 0.3609\n",
      "Epoch 63/150\n",
      "330/330 [==============================] - 0s 745us/step - loss: 1.9953 - accuracy: 0.2717 - mse: 0.3618\n",
      "Epoch 64/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.9933 - accuracy: 0.2696 - mse: 0.3598\n",
      "Epoch 65/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 1.9931 - accuracy: 0.2702 - mse: 0.3600\n",
      "Epoch 66/150\n",
      "330/330 [==============================] - 0s 757us/step - loss: 1.9908 - accuracy: 0.2731 - mse: 0.3607\n",
      "Epoch 67/150\n",
      "330/330 [==============================] - 0s 699us/step - loss: 1.9872 - accuracy: 0.2694 - mse: 0.3615\n",
      "Epoch 68/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 1.9853 - accuracy: 0.2709 - mse: 0.3600\n",
      "Epoch 69/150\n",
      "330/330 [==============================] - 0s 675us/step - loss: 1.9846 - accuracy: 0.2705 - mse: 0.3595\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "330/330 [==============================] - 0s 681us/step - loss: 1.9831 - accuracy: 0.2735 - mse: 0.3609\n",
      "Epoch 71/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 1.9821 - accuracy: 0.2716 - mse: 0.3599\n",
      "Epoch 72/150\n",
      "330/330 [==============================] - 0s 717us/step - loss: 1.9786 - accuracy: 0.2798 - mse: 0.3625\n",
      "Epoch 73/150\n",
      "330/330 [==============================] - 0s 724us/step - loss: 1.9741 - accuracy: 0.2723 - mse: 0.3614\n",
      "Epoch 74/150\n",
      "330/330 [==============================] - 0s 754us/step - loss: 1.9782 - accuracy: 0.2736 - mse: 0.3606\n",
      "Epoch 75/150\n",
      "330/330 [==============================] - 0s 797us/step - loss: 1.9717 - accuracy: 0.2767 - mse: 0.3608\n",
      "Epoch 76/150\n",
      "330/330 [==============================] - 0s 690us/step - loss: 1.9720 - accuracy: 0.2791 - mse: 0.3605\n",
      "Epoch 77/150\n",
      "330/330 [==============================] - 0s 757us/step - loss: 1.9737 - accuracy: 0.2780 - mse: 0.3614\n",
      "Epoch 78/150\n",
      "330/330 [==============================] - 0s 757us/step - loss: 1.9652 - accuracy: 0.2815 - mse: 0.3631\n",
      "Epoch 79/150\n",
      "330/330 [==============================] - 0s 751us/step - loss: 1.9649 - accuracy: 0.2789 - mse: 0.3619\n",
      "Epoch 80/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.9617 - accuracy: 0.2799 - mse: 0.3621\n",
      "Epoch 81/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.9648 - accuracy: 0.2843 - mse: 0.3627\n",
      "Epoch 82/150\n",
      "330/330 [==============================] - 0s 645us/step - loss: 1.9594 - accuracy: 0.2899 - mse: 0.3636\n",
      "Epoch 83/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 1.9570 - accuracy: 0.2770 - mse: 0.3622\n",
      "Epoch 84/150\n",
      "330/330 [==============================] - 0s 803us/step - loss: 1.9522 - accuracy: 0.2835 - mse: 0.3627\n",
      "Epoch 85/150\n",
      "330/330 [==============================] - 0s 730us/step - loss: 1.9513 - accuracy: 0.2824 - mse: 0.3658\n",
      "Epoch 86/150\n",
      "330/330 [==============================] - 0s 672us/step - loss: 1.9515 - accuracy: 0.2822 - mse: 0.3635\n",
      "Epoch 87/150\n",
      "330/330 [==============================] - 0s 678us/step - loss: 1.9503 - accuracy: 0.2834 - mse: 0.3645\n",
      "Epoch 88/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 1.9537 - accuracy: 0.2828 - mse: 0.3642\n",
      "Epoch 89/150\n",
      "330/330 [==============================] - 0s 687us/step - loss: 1.9449 - accuracy: 0.2856 - mse: 0.3661\n",
      "Epoch 90/150\n",
      "330/330 [==============================] - 0s 702us/step - loss: 1.9473 - accuracy: 0.2859 - mse: 0.3664\n",
      "Epoch 91/150\n",
      "330/330 [==============================] - 0s 687us/step - loss: 1.9473 - accuracy: 0.2840 - mse: 0.3644\n",
      "Epoch 92/150\n",
      "330/330 [==============================] - 0s 693us/step - loss: 1.9429 - accuracy: 0.2855 - mse: 0.3663\n",
      "Epoch 93/150\n",
      "330/330 [==============================] - 0s 696us/step - loss: 1.9381 - accuracy: 0.2911 - mse: 0.3666\n",
      "Epoch 94/150\n",
      "330/330 [==============================] - 0s 681us/step - loss: 1.9397 - accuracy: 0.2855 - mse: 0.3672\n",
      "Epoch 95/150\n",
      "330/330 [==============================] - 0s 693us/step - loss: 1.9358 - accuracy: 0.2909 - mse: 0.3692\n",
      "Epoch 96/150\n",
      "330/330 [==============================] - 0s 702us/step - loss: 1.9331 - accuracy: 0.2911 - mse: 0.3702\n",
      "Epoch 97/150\n",
      "330/330 [==============================] - 0s 705us/step - loss: 1.9365 - accuracy: 0.2859 - mse: 0.3700\n",
      "Epoch 98/150\n",
      "330/330 [==============================] - 0s 678us/step - loss: 1.9347 - accuracy: 0.2906 - mse: 0.3692\n",
      "Epoch 99/150\n",
      "330/330 [==============================] - 0s 696us/step - loss: 1.9314 - accuracy: 0.2895 - mse: 0.3699\n",
      "Epoch 100/150\n",
      "330/330 [==============================] - 0s 699us/step - loss: 1.9292 - accuracy: 0.2871 - mse: 0.3706\n",
      "Epoch 101/150\n",
      "330/330 [==============================] - 0s 821us/step - loss: 1.9287 - accuracy: 0.2934 - mse: 0.3709\n",
      "Epoch 102/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 1.9277 - accuracy: 0.2976 - mse: 0.3709\n",
      "Epoch 103/150\n",
      "330/330 [==============================] - 0s 754us/step - loss: 1.9264 - accuracy: 0.2974 - mse: 0.3724\n",
      "Epoch 104/150\n",
      "330/330 [==============================] - 0s 803us/step - loss: 1.9209 - accuracy: 0.2923 - mse: 0.3712\n",
      "Epoch 105/150\n",
      "330/330 [==============================] - 0s 803us/step - loss: 1.9188 - accuracy: 0.2962 - mse: 0.3736\n",
      "Epoch 106/150\n",
      "330/330 [==============================] - 0s 754us/step - loss: 1.9251 - accuracy: 0.2951 - mse: 0.3728\n",
      "Epoch 107/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 1.9186 - accuracy: 0.2907 - mse: 0.3745\n",
      "Epoch 108/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 1.9181 - accuracy: 0.2995 - mse: 0.3746\n",
      "Epoch 109/150\n",
      "330/330 [==============================] - 0s 641us/step - loss: 1.9194 - accuracy: 0.2945 - mse: 0.3721\n",
      "Epoch 110/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 1.9187 - accuracy: 0.2982 - mse: 0.3719\n",
      "Epoch 111/150\n",
      "330/330 [==============================] - 0s 666us/step - loss: 1.9144 - accuracy: 0.2951 - mse: 0.3736\n",
      "Epoch 112/150\n",
      "330/330 [==============================] - 0s 675us/step - loss: 1.9171 - accuracy: 0.2995 - mse: 0.3747\n",
      "Epoch 113/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 1.9112 - accuracy: 0.2954 - mse: 0.3735\n",
      "Epoch 114/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 1.9133 - accuracy: 0.2968 - mse: 0.3745\n",
      "Epoch 115/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 1.9101 - accuracy: 0.3011 - mse: 0.3743\n",
      "Epoch 116/150\n",
      "330/330 [==============================] - 0s 666us/step - loss: 1.9109 - accuracy: 0.3003 - mse: 0.3759\n",
      "Epoch 117/150\n",
      "330/330 [==============================] - 0s 800us/step - loss: 1.9061 - accuracy: 0.2953 - mse: 0.3764\n",
      "Epoch 118/150\n",
      "330/330 [==============================] - 0s 699us/step - loss: 1.9096 - accuracy: 0.3012 - mse: 0.3771\n",
      "Epoch 119/150\n",
      "330/330 [==============================] - 0s 687us/step - loss: 1.9064 - accuracy: 0.3031 - mse: 0.3767\n",
      "Epoch 120/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 1.9015 - accuracy: 0.3054 - mse: 0.3781\n",
      "Epoch 121/150\n",
      "330/330 [==============================] - 0s 648us/step - loss: 1.9027 - accuracy: 0.2970 - mse: 0.3772\n",
      "Epoch 122/150\n",
      "330/330 [==============================] - 0s 672us/step - loss: 1.9046 - accuracy: 0.2972 - mse: 0.3785\n",
      "Epoch 123/150\n",
      "330/330 [==============================] - 0s 699us/step - loss: 1.9006 - accuracy: 0.2973 - mse: 0.3793\n",
      "Epoch 124/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.8987 - accuracy: 0.2981 - mse: 0.3782\n",
      "Epoch 125/150\n",
      "330/330 [==============================] - 0s 666us/step - loss: 1.8976 - accuracy: 0.3037 - mse: 0.3771\n",
      "Epoch 126/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.8991 - accuracy: 0.3055 - mse: 0.3776\n",
      "Epoch 127/150\n",
      "330/330 [==============================] - 0s 654us/step - loss: 1.8988 - accuracy: 0.3029 - mse: 0.3793\n",
      "Epoch 128/150\n",
      "330/330 [==============================] - 0s 696us/step - loss: 1.8926 - accuracy: 0.3025 - mse: 0.3791\n",
      "Epoch 129/150\n",
      "330/330 [==============================] - 0s 678us/step - loss: 1.8947 - accuracy: 0.3021 - mse: 0.3789\n",
      "Epoch 130/150\n",
      "330/330 [==============================] - 0s 714us/step - loss: 1.8880 - accuracy: 0.3007 - mse: 0.3786\n",
      "Epoch 131/150\n",
      "330/330 [==============================] - 0s 727us/step - loss: 1.8936 - accuracy: 0.3083 - mse: 0.3809\n",
      "Epoch 132/150\n",
      "330/330 [==============================] - 0s 721us/step - loss: 1.8974 - accuracy: 0.3042 - mse: 0.3803\n",
      "Epoch 133/150\n",
      "330/330 [==============================] - 0s 684us/step - loss: 1.8868 - accuracy: 0.3022 - mse: 0.3808\n",
      "Epoch 134/150\n",
      "330/330 [==============================] - 0s 705us/step - loss: 1.8857 - accuracy: 0.3082 - mse: 0.3811\n",
      "Epoch 135/150\n",
      "330/330 [==============================] - 0s 721us/step - loss: 1.8849 - accuracy: 0.3047 - mse: 0.3793\n",
      "Epoch 136/150\n",
      "330/330 [==============================] - 0s 672us/step - loss: 1.8842 - accuracy: 0.3046 - mse: 0.3804\n",
      "Epoch 137/150\n",
      "330/330 [==============================] - 0s 717us/step - loss: 1.8838 - accuracy: 0.3053 - mse: 0.3815\n",
      "Epoch 138/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.8855 - accuracy: 0.3050 - mse: 0.3796\n",
      "Epoch 139/150\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "330/330 [==============================] - 0s 657us/step - loss: 1.8802 - accuracy: 0.3078 - mse: 0.3813\n",
      "Epoch 140/150\n",
      "330/330 [==============================] - 0s 690us/step - loss: 1.8806 - accuracy: 0.3120 - mse: 0.3820\n",
      "Epoch 141/150\n",
      "330/330 [==============================] - 0s 690us/step - loss: 1.8782 - accuracy: 0.3045 - mse: 0.3836\n",
      "Epoch 142/150\n",
      "330/330 [==============================] - 0s 678us/step - loss: 1.8820 - accuracy: 0.3107 - mse: 0.3832\n",
      "Epoch 143/150\n",
      "330/330 [==============================] - 0s 660us/step - loss: 1.8797 - accuracy: 0.3087 - mse: 0.3841\n",
      "Epoch 144/150\n",
      "330/330 [==============================] - 0s 669us/step - loss: 1.8772 - accuracy: 0.3065 - mse: 0.3825\n",
      "Epoch 145/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 1.8799 - accuracy: 0.3047 - mse: 0.3841\n",
      "Epoch 146/150\n",
      "330/330 [==============================] - 0s 733us/step - loss: 1.8793 - accuracy: 0.3071 - mse: 0.3835\n",
      "Epoch 147/150\n",
      "330/330 [==============================] - 0s 684us/step - loss: 1.8737 - accuracy: 0.3076 - mse: 0.3840\n",
      "Epoch 148/150\n",
      "330/330 [==============================] - 0s 663us/step - loss: 1.8741 - accuracy: 0.3102 - mse: 0.3836\n",
      "Epoch 149/150\n",
      "330/330 [==============================] - 0s 651us/step - loss: 1.8715 - accuracy: 0.3093 - mse: 0.3851\n",
      "Epoch 150/150\n",
      "330/330 [==============================] - 0s 657us/step - loss: 1.8709 - accuracy: 0.3060 - mse: 0.3861\n",
      "83/83 [==============================] - 0s 561us/step - loss: 2.1087 - accuracy: 0.2674 - mse: 0.3880\n",
      "The neural network testing MSE is:   0.38801723581133674\n",
      "The neural network training MSE is:   0.38415583763396177\n",
      "INFO:tensorflow:Assets written to: NN_model.sav\\assets\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}